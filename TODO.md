- make the local llama model use gpu correctly
    - currently i suspect only cpu is used, so its very slow

- make the combined api for transcription and notes generation

- make the demo ui to showcase both utility
